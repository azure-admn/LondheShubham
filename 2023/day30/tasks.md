## Day 30 Task: Kubernetes Architecture

<p  align="center"><img  align="center"  src="https://kubernetes.io/images/kubernetes-horizontal-color.png"  /></p>

## Kubernetes Overview

With the widespread adoption of [containers](https://cloud.google.com/containers) among organizations, Kubernetes, the container-centric management software, has become a standard to deploy and operate containerized applications and is one of the most important parts of DevOps. 

Originally developed at Google and released as open-source in 2014. Kubernetes builds on 15 years of running Google's containerized workloads and the valuable contributions from the open-source community. Inspired by Googleâ€™s internal cluster management system, [Borg](https://research.google.com/pubs/pub43438.html), 


## Tasks
1. What is Kubernetes? Write in your own words and why do we call it k8s?
Ans =>
Kubernetes (also known as "K8s") is an open-source container orchestration platform that automates the deployment, scaling, and management of containerized applications. It was originally developed by Google and is now maintained by the Cloud Native Computing Foundation (CNCF). Kubernetes provides a platform-agnostic way to manage containers, making it easier to deploy and scale applications across different environments.

In more technical terms, Kubernetes is a container orchestration system that automates the deployment, scaling, and management of containerized applications. It provides a set of APIs that allow developers to easily manage their applications, including features such as automatic scaling, rolling updates, and self-healing.

Kubernetes is called "K8s" because the word "Kubernetes" has 11 letters between "K" and "s". By replacing the 11 letters with the number 8, it creates a shorter, more concise abbreviation. This naming convention is known as "numeronym" and is commonly used in the tech industry.

2. What are the benefits of using k8s?
Ans =>
k8s is designed to automate the deployment, scaling, and management of containerized applications. Here are some benefits of using Kubernetes:

i. Scalability: Kubernetes enables you to scale your application up or down automatically based on the current demand. It can also add or remove containers dynamically, without any downtime.

ii. High availability: Kubernetes provides built-in features to ensure that your application is always available, even in the event of a node failure or network outage. It can automatically move containers to healthy nodes and restart failed containers.

iii. Flexibility: Kubernetes allows you to run your application on any infrastructure, whether it's on-premises or in the cloud. It also supports multiple container runtimes such as Docker and CRI-O.

iv. Portability: Kubernetes allows you to move your application between different environments without any modifications. This makes it easier to deploy and manage your application across multiple cloud providers or on-premises infrastructure.

v. Resource utilization: Kubernetes optimizes the use of resources by scheduling containers based on available resources and priorities. This ensures that resources are used efficiently and reduces costs.

vi. Automation: Kubernetes automates many of the manual tasks involved in deploying and managing containerized applications, reducing the risk of human error and speeding up the deployment process.

Overall, Kubernetes provides a powerful platform for managing containerized applications that can help to improve efficiency, reduce costs, and increase reliability.


3. Explain the architecture of Kubernetes, refer to [this video](https://youtube.com/FqfoDUhzyDo)
Ans =>
Kubernetes is an open-source container orchestration platform that is designed to automate the deployment, scaling, and management of containerized applications. The architecture of Kubernetes is based on a master-worker architecture, where the master node is responsible for managing the cluster and the worker nodes are responsible for running the containerized applications.

The Kubernetes architecture can be broken down into the following components:

i. Master Node: The master node is responsible for managing the Kubernetes cluster. It includes several components such as the API server, etcd, the scheduler, and the controller manager.
The API server provides a RESTful interface for managing the Kubernetes cluster.
etcd is a distributed key-value store that stores the state of the cluster.
The scheduler is responsible for scheduling containerized applications on the worker nodes.
The controller manager is responsible for managing the different controllers that automate the processes in the cluster.

ii. Worker Node: The worker node is responsible for running the containerized applications. It includes several components such as the kubelet, kube-proxy, and container runtime.
The kubelet is responsible for communicating with the API server to receive instructions on how to run the containerized applications.

iii. The kube-proxy is responsible for load balancing and network routing between the containers running on the worker node.
The container runtime is responsible for running the containerized applications on the worker node.

iv. Pods: Pods are the smallest deployable units in Kubernetes. A pod can contain one or more containers that share the same network namespace and can communicate with each other via the localhost.

v. Services: Services provide a way to expose the pods to the network. A service can be used to provide a stable IP address and DNS name for a group of pods that provide the same service.

vi. Replication Controllers: Replication controllers are responsible for ensuring that a specified number of pod replicas are running at any given time. If a pod goes down, the replication controller will automatically create a new pod to replace it.

vii. Deployments: Deployments provide a declarative way to manage the deployment of containerized applications. A deployment can be used to create and manage a set of replicas and update them with new container images or configuration changes.

Overall, the Kubernetes architecture provides a powerful and flexible platform for managing containerized applications at scale.

4. What is Control Plane?
Ans =>
In networking, the Control Plane refers to the part of a network architecture that is responsible for managing and directing the flow of data packets through the network. It is essentially the "brain" of the network, responsible for making decisions about how packets are forwarded, routed, and processed.

The Control Plane is distinct from the Data Plane, which is responsible for actually forwarding and processing the data packets themselves. While the Data Plane is focused on the efficient transmission of data, the Control Plane is focused on the overall operation and management of the network.

In a typical network architecture, the Control Plane is implemented using specialized hardware and software components, such as routers, switches, and controllers. These components work together to manage the network topology, monitor network traffic, and make decisions about how packets should be forwarded and processed.

Overall, the Control Plane is a critical component of any network architecture, as it enables network operators to efficiently manage and maintain their networks, while ensuring that data is transmitted quickly and reliably between different nodes in the network.

5. Write the difference between kubectl and kubelets.
Ans =>
Kubectl and Kubelet are both important components of Kubernetes, which is an open-source container orchestration platform. However, they have different roles and functionalities within the Kubernetes ecosystem. Here are the main differences between kubectl and kubelet:

i. Functionality:
kubectl is a command-line tool that enables you to interact with a Kubernetes cluster. It allows you to deploy, inspect, and manage applications and services running on the cluster. You can use kubectl to create, read, update, and delete Kubernetes resources, such as pods, deployments, and services.

Kubelet, on the other hand, is an agent that runs on each node in the Kubernetes cluster. Its main role is to manage and monitor the containers running on the node, as well as to ensure that they are running correctly.

ii. Usage:
kubectl is typically used by administrators and developers who want to manage the Kubernetes cluster and deploy applications on it. It provides a command-line interface that makes it easy to interact with the cluster and manage its resources.

Kubelet, on the other hand, is used by the Kubernetes control plane to manage the containers running on each node. It receives instructions from the control plane, such as which containers to run, and then ensures that they are running correctly.

iii. Deployment:
kubectl is deployed on the client machine or workstation, typically by installing the Kubernetes command-line tool.

Kubelet, on the other hand, is deployed on each node in the Kubernetes cluster, typically as a service or a daemon.

In summary, kubectl is a command-line tool for managing Kubernetes clusters, while kubelet is an agent that runs on each node in the cluster and manages the containers running on that node.

6. Explain the role of the API server.
Ans =>
An API server is a key component of a software application or system that provides access to its functionality and data through a set of standardized interfaces called Application Programming Interfaces (APIs). The API server acts as a gateway that enables different applications, services, or devices to communicate with the application or system, without requiring them to know the underlying implementation details.

The API server receives requests from clients that want to access the system's functionality or data, and then it processes those requests, validates them, and returns the appropriate responses. The API server may also perform other tasks, such as security and access control, caching, rate limiting, logging, and monitoring.

The API server is responsible for ensuring that the APIs are available, reliable, and scalable, and that they provide consistent and predictable behavior. It also helps to decouple the client applications from the underlying system, making it easier to change or update the system without affecting the clients.

In summary, the API server plays a crucial role in enabling different applications and systems to communicate with each other, by providing a standardized interface and ensuring the availability and reliability of the APIs.


Kubernetes architecture is important, so make sure you spend a day understanding it. [This video](https://youtu.be/FqfoDUhzyDo) will surely help you.  

*Happy Learning :)*